{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# MLflow Results Analysis\n",
    "\n",
    "This notebook fetches all trials from a given MLflow experiment for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Setup and Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import pydash as pyd\n",
    "import seaborn as sns\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# MLflow configuration\n",
    "TRACKING_URI = \"http://127.0.0.1:5001\"\n",
    "# EXPERIMENT_ID = \"413909140794424369\"  # graph-clf, batch norm\n",
    "EXPERIMENT_ID = \"740523204863010596\"  # graph-clf, hierarchical pooling layer\n",
    "\n",
    "DESIGN_CHOICE = \"HPOOLING\"\n",
    "\n",
    "print(f\"Connecting to MLflow server at: {TRACKING_URI}\")\n",
    "print(f\"Target experiment ID: {EXPERIMENT_ID}\")\n",
    "\n",
    "print(f\"DESIGN_CHOICE={DESIGN_CHOICE}\")\n",
    "if DESIGN_CHOICE == \"BN\":\n",
    "    design_choic_name = \"use_batchnorm\"\n",
    "    design_choice_data_path = \"data.params.model/post_mp_layer/use_batchnorm\"\n",
    "\n",
    "    metric_name = \"test_roc_auc\"\n",
    "    metric_data_path = \"data.metrics.test_roc_auc\"\n",
    "elif DESIGN_CHOICE == \"HPOOLING\":\n",
    "    design_choic_name = \"hpooling\"\n",
    "    design_choice_data_path = \"data.params.model/mp_layers/0/pooling/type\"\n",
    "\n",
    "    metric_name = \"test_roc_auc\"\n",
    "    metric_data_path = \"data.metrics.test_roc_auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tracking URI and create client\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "\n",
    "# Validate experiment exists\n",
    "try:\n",
    "    experiment = client.get_experiment(EXPERIMENT_ID)\n",
    "    print(f\"✓ Connected to experiment: {experiment.name}\")\n",
    "    print(f\"  Experiment ID: {experiment.experiment_id}\")\n",
    "    print(f\"  Lifecycle stage: {experiment.lifecycle_stage}\")\n",
    "    print(f\"  Artifact location: {experiment.artifact_location}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error accessing experiment: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all runs from the experiment\n",
    "print(\"Fetching all runs from the experiment...\")\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[EXPERIMENT_ID],\n",
    "    max_results=10000,  # Adjust if you expect more runs\n",
    ")\n",
    "\n",
    "print(f\"Found {len(runs)} runs in the experiment\")\n",
    "\n",
    "if len(runs) == 0:\n",
    "    print(\"No runs found in this experiment.\")\n",
    "else:\n",
    "    print(f\"Run status breakdown:\")\n",
    "    status_counts = {}\n",
    "    for run in runs:\n",
    "        status = run.info.status\n",
    "        status_counts[status] = status_counts.get(status, 0) + 1\n",
    "\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"  {status}: {count} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = pyd.map_(\n",
    "    runs,\n",
    "    lambda r: {\n",
    "        \"group_id\": pyd.get(r, \"data.tags.group_id\"),\n",
    "        metric_name: pyd.get(r, metric_data_path),\n",
    "        design_choic_name: pyd.get(r, design_choice_data_path),\n",
    "        \"run_status\": pyd.get(r, \"info.status\"),\n",
    "    },\n",
    ")\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.sort_values(by=[\"group_id\", design_choic_name])\n",
    "df[\"rank\"] = df.groupby(\"group_id\")[metric_name].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out groups in which some runs failed\n",
    "df = df.groupby(\"group_id\").filter(lambda x: (x[\"run_status\"] == \"FINISHED\").all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby(design_choic_name)[\"rank\"].agg([\"mean\", \"count\"]).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82e0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(df, hue=design_choic_name, y=\"rank\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stgym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
